# -*- coding: utf-8 -*-
"""NeuralNetworks.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GmIL6tLADAHhk1kHslSccqLzKxBrDkK1

Sandhya M 2448142
"""

#@title ⬇️ Install & Imports
!pip -q install tensorflow==2.15.0 tensorflow-addons==0.23.0

import os, zipfile, shutil, random, pathlib, itertools
import numpy as np
import tensorflow as tf
import tensorflow_addons as tfa
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report
from google.colab import drive, files

print(tf.__version__)
tf.random.set_seed(42)
np.random.seed(42)

# Step 2 — Mount Google Drive and set dataset path

from google.colab import drive
drive.mount('/content/drive')

# Path to your dataset (adjust if your folder is in another location in Drive)
dataset_dir = "/content/drive/MyDrive/DatasetRoot"

# Check the folder structure
import os
print("Folders in DatasetRoot:", os.listdir(dataset_dir))

# Step 3 — View 2 raw images from each folder

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import random
import os

folders = ["Car_Images", "Auto_Images", "Bike_Images"]

plt.figure(figsize=(10, 6))

i = 1
for folder in folders:
    folder_path = os.path.join(dataset_dir, folder)
    # Pick any 2 random images
    samples = random.sample(os.listdir(folder_path), 2)
    for img_name in samples:
        img_path = os.path.join(folder_path, img_name)
        img = mpimg.imread(img_path)

        plt.subplot(len(folders), 2, i)
        plt.imshow(img)
        plt.title(f"{folder} - {img_name}", fontsize=8)
        plt.axis("off")
        i += 1

plt.tight_layout()
plt.show()

# Step 4 — Preprocessing & Augmentation (build tf.data pipelines)

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt

# ---- Config ----
IMG_SIZE = (224, 224)
BATCH_SIZE = 8
VAL_SPLIT = 0.2
SEED = 1337

# 4.1 Load datasets (train/val split)
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    dataset_dir,
    validation_split=VAL_SPLIT,
    subset="training",
    seed=SEED,
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    dataset_dir,
    validation_split=VAL_SPLIT,
    subset="validation",
    seed=SEED,
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
)

class_names = train_ds.class_names
print("Classes:", class_names)

# ---- Performance tweaks ----
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().shuffle(256, seed=SEED).prefetch(AUTOTUNE)
val_ds   = val_ds.cache().prefetch(AUTOTUNE)

# 4.2 Preprocessing: rescale + (optional) light Gaussian blur
def gaussian_kernel(ksize=3, sigma=0.8):
    ax = tf.range(-ksize//2 + 1, ksize//2 + 1, dtype=tf.float32)
    xx, yy = tf.meshgrid(ax, ax)
    kernel = tf.exp(-(xx**2 + yy**2)/(2.0*sigma**2))
    kernel = kernel / tf.reduce_sum(kernel)
    kernel = tf.reshape(kernel, (ksize, ksize, 1, 1))
    kernel = tf.repeat(kernel, repeats=3, axis=2)  # RGB
    return kernel

class DenoiseGaussian(layers.Layer):
    def __init__(self, ksize=3, sigma=0.8, **kwargs):
        super().__init__(**kwargs)
        self.ksize = ksize
        self.sigma = sigma
        self.kernel = gaussian_kernel(ksize, sigma)

    def call(self, x):
        # x expected in [0,1]
        return tf.nn.depthwise_conv2d(x, self.kernel, strides=[1,1,1,1], padding="SAME")

preprocess = keras.Sequential([
    layers.Rescaling(1./255),
    DenoiseGaussian(ksize=3, sigma=0.8),   # comment this line out if you don't want blur
], name="preprocess")

# 4.3 Augmentations
augment = keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.08),
    layers.RandomZoom(0.08),
    layers.RandomContrast(0.1),
    layers.RandomBrightness(factor=0.1),
], name="augment")

# 4.4 Map pipelines: apply preprocess (+ augment only for train)
def map_train(x, y):
    x = preprocess(x)
    x = augment(x)
    return x, y

def map_eval(x, y):
    x = preprocess(x)
    return x, y

train_ds_aug = train_ds.map(map_train, num_parallel_calls=AUTOTUNE)
val_ds_prep  = val_ds.map(map_eval,  num_parallel_calls=AUTOTUNE)

print("Pipelines ready.")

# Step 4.x — Visualize raw vs. preprocessed/augmented batches

import numpy as np
import matplotlib.pyplot as plt

def show_batch(ds, class_names, title, expect_float=False, max_images=9):
    # grab one batch
    imgs, labels = next(iter(ds.take(1)))
    imgs = imgs.numpy()
    labels = labels.numpy()

    # clip / cast for correct display
    if expect_float:
        imgs = np.clip(imgs, 0.0, 1.0)           # after Rescaling(1./255) and aug
    else:
        imgs = imgs.astype("uint8")              # raw loader gives uint8 [0..255]

    n = min(max_images, imgs.shape[0])
    cols = 3
    rows = int(np.ceil(n / cols))
    plt.figure(figsize=(4*cols, 3*rows))
    for i in range(n):
        plt.subplot(rows, cols, i+1)
        plt.imshow(imgs[i])
        plt.axis("off")
        plt.title(f"{class_names[int(labels[i])]}", fontsize=10)
    plt.suptitle(title, fontsize=14)
    plt.tight_layout()
    plt.show()

# A) RAW (direct output from image_dataset_from_directory)
show_batch(train_ds, class_names, title="RAW samples (before preprocess/augment)", expect_float=False)

# B) TRAIN (after preprocess + augment)  -> expect floats in [0,1]
show_batch(train_ds_aug, class_names, title="TRAIN samples (after preprocess + augmentation)", expect_float=True)

# C) VAL (after preprocess only) -> expect floats in [0,1]
show_batch(val_ds_prep, class_names, title="VAL samples (after preprocess only)", expect_float=True)

train_count = tf.data.experimental.cardinality(train_ds).numpy()
val_count   = tf.data.experimental.cardinality(val_ds).numpy()

print("Train images:", train_count * BATCH_SIZE)
print("Val images:", val_count * BATCH_SIZE)

# Step 5 — Define and train a simple CNN

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

NUM_CLASSES = len(class_names)  # from earlier

def build_simple_cnn(input_shape=(224, 224, 3), num_classes=3):
    inputs = keras.Input(shape=input_shape)

    x = layers.Conv2D(32, 3, padding="same", activation="relu")(inputs)
    x = layers.MaxPooling2D()(x)

    x = layers.Conv2D(64, 3, padding="same", activation="relu")(x)
    x = layers.MaxPooling2D()(x)

    x = layers.Conv2D(128, 3, padding="same", activation="relu")(x)
    x = layers.MaxPooling2D()(x)

    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dropout(0.3)(x)
    x = layers.Dense(128, activation="relu")(x)
    x = layers.Dropout(0.3)(x)

    outputs = layers.Dense(num_classes, activation="softmax")(x)
    return keras.Model(inputs, outputs, name="vehicle_simple_cnn")

model = build_simple_cnn(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), num_classes=NUM_CLASSES)
model.summary()

model.compile(
    optimizer=keras.optimizers.Adam(1e-3),
    loss="sparse_categorical_crossentropy",   # labels are integers from image_dataset_from_directory
    metrics=["accuracy"],
)

callbacks = [
    keras.callbacks.EarlyStopping(monitor="val_accuracy", patience=5, restore_best_weights=True),
    keras.callbacks.ModelCheckpoint("best_vehicle_cnn.keras", monitor="val_accuracy", save_best_only=True),
    keras.callbacks.ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=2, min_lr=1e-6)
]

EPOCHS = 25
history = model.fit(
    train_ds_aug,
    validation_data=val_ds_prep,
    epochs=EPOCHS,
    callbacks=callbacks,
    verbose=1
)

# quick validation performance
val_loss, val_acc = model.evaluate(val_ds_prep, verbose=0)
print(f"Validation accuracy: {val_acc:.3f}  |  loss: {val_loss:.3f}")
print("Saved best model to: best_vehicle_cnn.keras")

# Step 5 — Build & train a simple CNN classifier

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import json, os
import matplotlib.pyplot as plt

num_classes = len(class_names)
input_shape = (IMG_SIZE[0], IMG_SIZE[1], 3)

# 5.1 Define a lightweight CNN (kept simple & TF2.16+ compatible)
def build_cnn(input_shape, num_classes):
    inputs = keras.Input(shape=input_shape)

    x = layers.Conv2D(32, 3, padding="same", activation="relu")(inputs)
    x = layers.BatchNormalization()(x)
    x = layers.MaxPooling2D()(x)

    x = layers.Conv2D(64, 3, padding="same", activation="relu")(x)
    x = layers.BatchNormalization()(x)
    x = layers.MaxPooling2D()(x)

    x = layers.Conv2D(128, 3, padding="same", activation="relu")(x)
    x = layers.BatchNormalization()(x)
    x = layers.MaxPooling2D()(x)

    x = layers.Dropout(0.25)(x)
    x = layers.Conv2D(128, 3, padding="same", activation="relu")(x)
    x = layers.BatchNormalization()(x)
    x = layers.GlobalAveragePooling2D()(x)

    x = layers.Dropout(0.3)(x)
    outputs = layers.Dense(num_classes, activation="softmax")(x)
    return keras.Model(inputs, outputs, name="simple_cnn")

model = build_cnn(input_shape, num_classes)
model.summary()

# 5.2 Compile
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=1e-3),
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

# 5.3 Callbacks
ckpt_dir = "checkpoints"
os.makedirs(ckpt_dir, exist_ok=True)
callbacks = [
    keras.callbacks.ModelCheckpoint(
        filepath=os.path.join(ckpt_dir, "best.keras"),
        monitor="val_accuracy",
        save_best_only=True,
        verbose=1
    ),
    keras.callbacks.ReduceLROnPlateau(
        monitor="val_loss", factor=0.5, patience=3, min_lr=1e-5, verbose=1
    ),
    keras.callbacks.EarlyStopping(
        monitor="val_accuracy", patience=6, restore_best_weights=True, verbose=1
    ),
]

# 5.4 Train
EPOCHS = 25
history = model.fit(
    train_ds_aug,
    validation_data=val_ds_prep,
    epochs=EPOCHS,
    callbacks=callbacks
)

# 5.5 Evaluate
val_loss, val_acc = model.evaluate(val_ds_prep, verbose=0)
print(f"\nValidation accuracy: {val_acc:.3f} | loss: {val_loss:.3f}")

# 5.6 Plot learning curves
plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
plt.plot(history.history["accuracy"], label="train")
plt.plot(history.history["val_accuracy"], label="val")
plt.title("Accuracy"); plt.xlabel("Epoch"); plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history["loss"], label="train")
plt.plot(history.history["val_loss"], label="val")
plt.title("Loss"); plt.xlabel("Epoch"); plt.legend()
plt.tight_layout()
plt.show()

# 5.7 Save model + classes for inference step
model.save("vehicle_cnn.keras")  # SavedModel (Keras v3 format)
with open("class_names.json", "w") as f:
    json.dump(class_names, f)

print("Saved: vehicle_cnn.keras and class_names.json")

# Step 6 — Upload & classify a single image

import json, numpy as np, tensorflow as tf
from tensorflow import keras
from google.colab import files
import matplotlib.pyplot as plt

# Load model & class names (from Step 5 saves)
model = keras.models.load_model("vehicle_cnn.keras", compile=False)
with open("class_names.json", "r") as f:
    class_names = json.load(f)

IMG_SIZE = (224, 224)  # same as training

def preprocess_for_inference(img_path):
    img = tf.keras.utils.load_img(img_path, target_size=IMG_SIZE)
    x = tf.keras.utils.img_to_array(img)
    x = x / 255.0  # match layers.Rescaling(1./255) used in training pipeline
    x = np.expand_dims(x, axis=0)
    return img, x

def predict_image(img_path):
    pil_img, x = preprocess_for_inference(img_path)
    probs = model.predict(x, verbose=0)[0]
    pred_idx = int(np.argmax(probs))
    pred_label = class_names[pred_idx]
    return pil_img, pred_label, probs

print("Upload a jpg/png to classify:")
uploaded = files.upload()
fname = next(iter(uploaded.keys()))

pil_img, label, probs = predict_image(fname)

plt.imshow(pil_img)
plt.axis("off")
plt.title(f"Prediction: {label}\n" +
          ", ".join([f"{n}: {probs[i]:.2f}" for i, n in enumerate(class_names)]),
          fontsize=9)
plt.show()

print("Scores:", {n: float(probs[i]) for i, n in enumerate(class_names)})
print("Predicted class:", label)
